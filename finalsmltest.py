# -*- coding: utf-8 -*-
"""FinalSMLtest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BA9zwa5K8t-9rVjtoRGkVGqCP2C7-AP3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier,BaggingClassifier
import seaborn as sn
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix,roc_auc_score, roc_curve
from sklearn.model_selection import cross_val_predict,RepeatedStratifiedKFold,cross_val_score,train_test_split
from sklearn.metrics import classification_report
def min_max_scaling(series):
    return (series - series.min()) / (series.max() - series.min())

"""Data Retreving and Cleaning And Normalizing"""

pd.set_option('display.max_columns',None) #maximize the wodth of the columns
data = pd.read_csv('train.csv')
#Number words female[0] - 21
#Number words male[0]- 5
for i,each in enumerate(data['Number words male']):
  #print(each)
  if (each == 0):
      data['Number words male'][i] = data['Total words'][i]-data['Number of words lead'][i]-data["Number words female"][i] #computing the values of zero
for j, each in enumerate(data['Number words female']):
  if (each==0):
    #print(data['Number words male'][i])
      data['Number words female'][j] = data['Total words'][j]-data['Number of words lead'][j]-data["Number words male"][j] #computing the values of zero    #print(i)

for j, each in enumerate(data['Lead']):
  if (each=="Female"):
    data['Lead'][j] = 1
  elif (each=="Male"):
    data['Lead'][j] = 0

for col in data.columns:
    data[col] = min_max_scaling(data[col])
data.head()
print(data.var())
# Dropping the feature
data=data.drop([],axis=1)
data.head()
data_X = data.iloc[:,:-1]
data_y = data.iloc[:,-1]

"""Algorithms

*Splitting* the data
"""

x_for_cv, x_test_last,y_for_cv,y_test_last =train_test_split(data_X,data_y, test_size=0.05) # last test
x_test_last = np.asarray(x_test_last)
x_test_last = x_test_last.tolist()
y_test_last = np.asarray(y_test_last)
y_test_last = y_test_last.tolist()
x_train, x_test,y_train,y_test =train_test_split(x_for_cv,y_for_cv, test_size=0.2) 
y_train = np.asarray(y_train)
y_train = y_train.tolist()
x_train = np.asarray(x_train)
x_train = x_train.tolist()
x_test = np.asarray(x_test)
x_test = x_test.tolist()
y_test = np.asarray(y_test)
y_test = y_test.tolist()

"""Decision Tree"""

model= DecisionTreeClassifier()
model.fit(x_train,y_train)
print(model.score(x_test,y_test))
y_predicted1=model.predict(x_test) #to see the distribution of the errors and where my model performs well and where it doesnt
print('Error btween the predicted and the test', sum(y_test-y_predicted1))
#confusion matrix helps in predicting the truth on one side and the actual on other axis
cm= confusion_matrix(y_test,y_predicted1)
plt.figure(figsize=(5,3))
sn.heatmap(cm,annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')
print(classification_report(y_test,model.predict(x_test)))

"""Random Foreset """

model1= RandomForestClassifier(n_estimators= 1000, criterion = 'gini',max_depth=20, random_state=1500,min_samples_split = 3)
model1.fit(x_train,y_train)
y_predicted2=model1.predict(x_test) #to see the distribution of the errors and where my model performs well and where it doesnt
print('Acurracy',model1.score(x_test,y_test))

#print('Errors',abs(y_predicted2 - y_test))
#confusion matrix helps in predicting the truth on one side and the actual on other axis
from sklearn.metrics import confusion_matrix
import seaborn as sn
cm= confusion_matrix(y_test,y_predicted2)
plt.figure(figsize=(5,3))
sn.heatmap(cm,annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

print(classification_report(y_test,model1.predict(x_test)))

"""Test with new data"""

cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
model2=BaggingClassifier(base_estimator=RandomForestClassifier(),n_estimators=100,max_samples=0.8,oob_score=True,random_state=0)
data_X = np.asarray(data_X)
data_X = data_X.tolist()
data_y = np.asarray(data_y)
data_y = data_y.tolist()
n_scores = cross_val_score(model2, data_X, data_y, scoring='accuracy', cv=cv)
print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))